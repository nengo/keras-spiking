
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Classifying Fashion MNIST with spiking activations &#8212; KerasSpiking 0.3.1.dev0 docs</title>
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
<link rel="preconnect" href="https://fonts.googleapis.com"/>
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
<link href="https://fonts.googleapis.com/css2?family=DM+Sans:ital,wght@0,400;0,500;0,700;1,400;1,500;1,700&family=Space+Grotesk:wght@400;700&display=swap" rel="stylesheet" />
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.2/css/all.css" integrity="sha384-oS3vJWv+0UjzBfQzYUhtDYW+Pj2yciDJxpsK1OYPAYjqT085Qq/1cq5FLXAZQ7Ay" crossorigin="anonymous">
<link rel="stylesheet" href="https://www.nengo.ai/css/bootstrap.css" type="text/css">
<style>
 body .title-bar,
 body .documentation-source h1:after {
   background-color: #a8acaf;
 }
</style>
<script src="https://code.jquery.com/jquery-3.3.1.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js" integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49" crossorigin="anonymous"></script>
<script src="https://unpkg.com/scrollreveal"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/stickyfill/2.1.0/stickyfill.min.js"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.1/js/bootstrap.min.js" integrity="sha384-smHYKdLADwkXOn1EmN1qk/HfnUcbVRZyYmZ4qpPea6sjB/pTJ0euyQp0Mk8ck+5T" crossorigin="anonymous"></script>
<!-- From basic/layout.html -->
<script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>


<script src="../_static/underscore.js"></script>


<script src="../_static/doctools.js"></script>


<script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>


<script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>


<script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "tex2jax_ignore|mathjax_ignore|document", "processClass": "tex2jax_process|mathjax_process|math|output_area"}})</script>

        <!-- Google tag (gtag.js) -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=G-GT8XEDLTMJ"></script>
        <script>
         window.dataLayer = window.dataLayer || [];
         function gtag(){dataLayer.push(arguments);}
         gtag('js', new Date());
         gtag('config', 'G-GT8XEDLTMJ');
        </script>
        <!-- End Google tag (gtag.js) -->
        <!-- Matomo -->
        <script>
         var _paq = window._paq = window._paq || [];
         _paq.push(["setDocumentTitle", document.domain + "/" + document.title]);
         _paq.push(["setCookieDomain", "*.appliedbrainresearch.com"]);
         _paq.push(["setDomains", ["*.appliedbrainresearch.com","*.edge.nengo.ai","*.forum.nengo.ai","*.labs.nengo.ai","*.nengo.ai"]]);
         _paq.push(["enableCrossDomainLinking"]);
         _paq.push(["setDoNotTrack", true]);
         _paq.push(['trackPageView']);
         _paq.push(['enableLinkTracking']);
         (function() {
           var u="https://appliedbrainresearch.matomo.cloud/";
           _paq.push(['setTrackerUrl', u+'matomo.php']);
           _paq.push(['setSiteId', '3']);
           var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
           g.async=true; g.src='//cdn.matomo.cloud/appliedbrainresearch.matomo.cloud/matomo.js'; s.parentNode.insertBefore(g,s);
         })();
        </script>
        <!-- End Matomo Code -->
    
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Estimating model energy" href="model-energy.html" />
    <link rel="prev" title="Examples" href="../examples.html" />
<meta name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover">

  </head><body class="bg-dark">

<header class="fixed-top header-top shadow-sm">
  <nav class="navbar navbar-expand-md navbar-light bg-white">
    <a class="navbar-brand" href="https://www.nengo.ai/">
      <img
        src="https://www.nengo.ai/design/_images/general-full-light.svg"
        alt="Nengo"
        class="logo"
      />
    </a>
    <button
      class="navbar-toggler"
      type="button"
      data-toggle="collapse"
      data-target="#navbar-collapse"
      aria-controls="navbar-collapse"
      aria-expanded="false"
      aria-label="Toggle navigation"
    >
      <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse" id="navbar-collapse">
      <ul class="navbar-nav ml-auto">
        <li class="nav-item">
          <a class="nav-link" href="https://www.nengo.ai/">What is Nengo?</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://www.nengo.ai/examples/">Examples</a>
        </li>
        <li class="nav-item dropdown active">
          <a
            class="nav-link dropdown-toggle"
            id="navbar-dropdown-docs"
            data-toggle="dropdown"
            aria-haspopup="true"
            aria-expanded="false"
            href="#"
            >Documentation</a
          >
          <div
            class="dropdown-menu shadow-lg border-0"
            aria-labelledby="navbar-dropdown-docs"
          >
            
            <a class="dropdown-item" href="https://www.nengo.ai/nengo/">Nengo core</a>
            <a class="dropdown-item" href="https://github.com/nengo/nengo-gui/">NengoGUI</a>
            <a class="dropdown-item" href="https://www.nengo.ai/nengo-dl/">NengoDL</a>
            <div class="dropdown-divider"></div>
            <a class="dropdown-item" href="https://www.nengo.ai/nengo-spa/">NengoSPA</a>
            <a class="dropdown-item" href="https://www.nengo.ai/nengo-extras/">NengoExtras</a>
            <a class="dropdown-item" href="https://arvoelke.github.io/nengolib-docs/">Nengolib</a>
            <a class="dropdown-item" href="https://www.nengo.ai/keras-spiking">KerasSpiking</a>
            <a class="dropdown-item" href="https://www.nengo.ai/pytorch-spiking">PyTorchSpiking</a>
            <div class="dropdown-divider"></div>
            <a class="dropdown-item" href="https://www.nengo.ai/nengo-fpga/">NengoFPGA</a>
            <a class="dropdown-item" href="https://www.nengo.ai/nengo-loihi/">NengoLoihi</a>
            <a class="dropdown-item" href="https://labs.nengo.ai/nengo-ocl/">NengoOCL</a>
            <a class="dropdown-item" href="https://github.com/project-rig/nengo_spinnaker">NengoSpiNNaker</a>
            <a class="dropdown-item" href="https://github.com/nengo-labs/nengo-mpi">NengoMPI</a>
            <div class="dropdown-divider"></div>
            <a class="dropdown-item" href="https://www.nengo.ai/documentation/"
              >All documentation</a
            >
          </div>
        </li>
        <li class="nav-item dropdown">
          <a
            class="nav-link dropdown-toggle"
            id="navbar-dropdown-community"
            data-toggle="dropdown"
            aria-haspopup="true"
            aria-expanded="false"
            href="#"
            >Community</a
          >
          <div
            class="dropdown-menu shadow-lg border-0"
            aria-labelledby="navbar-dropdown-community"
          >
            <a class="dropdown-item" href="https://forum.nengo.ai">Forum</a>
            <div class="dropdown-divider"></div>
            <a class="dropdown-item" href="https://www.nengo.ai/people/"
              >People</a
            >
            <a class="dropdown-item" href="https://www.nengo.ai/summer-school/"
              >Summer school</a
            >
            <a class="dropdown-item" href="https://www.nengo.ai/contributing/"
              >Contributing</a
            >
            <a class="dropdown-item" href="https://www.nengo.ai/publications/"
              >Publications</a
            >
            <a class="dropdown-item" href="https://www.nengo.ai/videos/"
              >Videos</a
            >
            <a class="dropdown-item" href="https://www.nengo.ai/conduct/"
              >Code of conduct</a
            >
            <a class="dropdown-item" href="https://www.nengo.ai/caa/">CAA</a>
          </div>
        </li>
      </ul>
      <ul class="navbar-nav ml-auto">
        <li class="nav-item">
          <a
            class="nav-link btn btn-success btn-sm text-white"
            href="https://www.nengo.ai/getting-started/"
          >Getting started</a
        >
        </li>
        <li class="nav-item">
          <a
            class="nav-link btn btn-success btn-sm text-white"
            href="https://www.nengo.ai/store/"
          >Store</a
        >
        </li>
      </ul>
    </div>
  </nav>
</header>
<div class="main-content gradient-top">
  <div class="container-fluid">
    <div class="row"><a class="toggle-sidenav d-block d-md-none" href="#"
  ><i class="icon-close fa fa-fw fa-arrow-left"></i
  ><i class="icon-open fa fa-fw fa-arrow-right"></i
></a>
<div role="complementary" class="sidenav col-4 col-xl-3 p-0 border-right">
  <h3 class="pt-5 px-5">
    <a href="../index.html">
      KerasSpiking
    </a>
  </h3>
<form class="px-5 py-3 my-0 border-bottom" action="../search.html" method="get">
  <div class="form-group form-group-single">
    <input type="text" name="q" class="form-control" placeholder="Search" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
    <button type="submit" class="btn btn-link">
      <img src="https://www.nengo.ai/img/icon-search.svg" alt="Go" />
    </button>
  </div>
</form><div class="p-5 toctree">
  
    <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../examples.html">Examples</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">Classifying Fashion MNIST with spiking activations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Loading-data">Loading data</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Non-spiking-model">Non-spiking model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Spiking-model">Spiking model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Simulation-time">Simulation time</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Spiking-aware-training">Spiking aware training</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Spike-rate-regularization">Spike rate regularization</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Lowpass-filtering">Lowpass filtering</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Summary">Summary</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="model-energy.html">Estimating model energy</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../reference.html">API reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../project.html">Project information</a></li>
</ul>

  
  </div>
  
</div>
      

      <div class="col-12 col-md-8 col-xl-9">
        <div class="container">
          <div class="row">
            <div class="col-10 offset-1 pb-5 documentation-source" role="main">
              
              
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars and line breaks on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
    white-space: pre;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt .copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
.jp-RenderedHTMLCommon table,
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
.jp-RenderedHTMLCommon thead,
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
.jp-RenderedHTMLCommon tr,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon td,
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
.jp-RenderedHTMLCommon th,
div.rendered_html th {
  font-weight: bold;
}
.jp-RenderedHTMLCommon tbody tr:nth-child(odd),
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
.jp-RenderedHTMLCommon tbody tr:hover,
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
</style>
<div class="section" id="Classifying-Fashion-MNIST-with-spiking-activations">
<h1>Classifying Fashion MNIST with spiking activations<a class="headerlink" href="#Classifying-Fashion-MNIST-with-spiking-activations" title="Permalink to this headline">¶</a></h1>
<p><a class="reference external" href="https://colab.research.google.com/github/nengo/keras-spiking/blob/master/docs/examples/spiking-fashion-mnist.ipynb"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></p>
<p>This example is based on the <a class="reference external" href="https://www.tensorflow.org/tutorials/keras/classification">Basic image classification example in TensorFlow</a>. We would recommend beginning there if you would like a more basic introduction to how Keras works. In this example we will walk through how we can convert that non-spiking model into a spiking model using KerasSpiking, and various techniques that can be used to fine tune performance.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="kn">import</span> <span class="nn">keras_spiking</span>

<span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
2023-02-08 15:24:15.844065: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
</pre></div></div>
</div>
<div class="section" id="Loading-data">
<h2>Loading data<a class="headerlink" href="#Loading-data" title="Permalink to this headline">¶</a></h2>
<p>We’ll begin by loading the Fashion MNIST data:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="p">(</span>
    <span class="p">(</span><span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">),</span>
    <span class="p">(</span><span class="n">test_images</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">),</span>
<span class="p">)</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">fashion_mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>

<span class="c1"># normalize images so values are between 0 and 1</span>
<span class="n">train_images</span> <span class="o">=</span> <span class="n">train_images</span> <span class="o">/</span> <span class="mf">255.0</span>
<span class="n">test_images</span> <span class="o">=</span> <span class="n">test_images</span> <span class="o">/</span> <span class="mf">255.0</span>

<span class="n">class_names</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;T-shirt/top&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Trouser&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Pullover&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Dress&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Coat&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Sandal&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Shirt&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Sneaker&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Bag&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Ankle boot&quot;</span><span class="p">,</span>
<span class="p">]</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">class_names</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">25</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">train_images</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">binary</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">class_names</span><span class="p">[</span><span class="n">train_labels</span><span class="p">[</span><span class="n">i</span><span class="p">]])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_spiking-fashion-mnist_3_0.png" src="../_images/examples_spiking-fashion-mnist_3_0.png" />
</div>
</div>
</div>
<div class="section" id="Non-spiking-model">
<h2>Non-spiking model<a class="headerlink" href="#Non-spiking-model" title="Permalink to this headline">¶</a></h2>
<p>Next we’ll build and train the non-spiking model (this is identical to the <a class="reference external" href="https://www.tensorflow.org/tutorials/keras/classification">original TensorFlow example</a>).</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)),</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">),</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span>
    <span class="p">]</span>
<span class="p">)</span>


<span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">input_model</span><span class="p">,</span> <span class="n">train_x</span><span class="p">,</span> <span class="n">test_x</span><span class="p">):</span>
    <span class="n">input_model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
        <span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;adam&quot;</span><span class="p">,</span>
        <span class="n">loss</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">(</span><span class="n">from_logits</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
        <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
    <span class="p">)</span>

    <span class="n">input_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

    <span class="n">_</span><span class="p">,</span> <span class="n">test_acc</span> <span class="o">=</span> <span class="n">input_model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">test_x</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Test accuracy:&quot;</span><span class="p">,</span> <span class="n">test_acc</span><span class="p">)</span>


<span class="n">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_images</span><span class="p">,</span> <span class="n">test_images</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
2023-02-08 15:24:26.266706: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-02-08 15:24:26.849011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10784 MB memory:  -&gt; device: 0, name: Tesla K80, pci bus id: 0001:00:00.0, compute capability: 3.7
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Epoch 1/10
1875/1875 [==============================] - 4s 2ms/step - loss: 0.5037 - accuracy: 0.8243
Epoch 2/10
1875/1875 [==============================] - 3s 2ms/step - loss: 0.3762 - accuracy: 0.8656
Epoch 3/10
1875/1875 [==============================] - 3s 2ms/step - loss: 0.3365 - accuracy: 0.8774
Epoch 4/10
1875/1875 [==============================] - 3s 2ms/step - loss: 0.3135 - accuracy: 0.8851
Epoch 5/10
1875/1875 [==============================] - 3s 2ms/step - loss: 0.2972 - accuracy: 0.8906
Epoch 6/10
1875/1875 [==============================] - 3s 2ms/step - loss: 0.2816 - accuracy: 0.8974
Epoch 7/10
1875/1875 [==============================] - 3s 2ms/step - loss: 0.2721 - accuracy: 0.8990
Epoch 8/10
1875/1875 [==============================] - 3s 2ms/step - loss: 0.2626 - accuracy: 0.9027
Epoch 9/10
1875/1875 [==============================] - 3s 2ms/step - loss: 0.2501 - accuracy: 0.9069
Epoch 10/10
1875/1875 [==============================] - 3s 2ms/step - loss: 0.2414 - accuracy: 0.9102
313/313 - 1s - loss: 0.3637 - accuracy: 0.8741 - 572ms/epoch - 2ms/step

Test accuracy: 0.8741000294685364
</pre></div></div>
</div>
</div>
<div class="section" id="Spiking-model">
<h2>Spiking model<a class="headerlink" href="#Spiking-model" title="Permalink to this headline">¶</a></h2>
<p>Next we will create an equivalent spiking model. There are three important changes here:</p>
<ol class="arabic simple">
<li><p>Add a temporal dimension to the data/model.</p></li>
</ol>
<p>Spiking models always run over time (i.e., each forward pass through the model will run for some number of timesteps). This means that we need to add a temporal dimension to the data, so instead of having shape <code class="docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">...)</span></code> it will have shape <code class="docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">n_steps,</span> <span class="pre">...)</span></code>. For those familiar with working with RNNs, the principles are the same; a spiking neuron accepts temporal data and computes over time, just like an RNN.</p>
<ol class="arabic simple" start="2">
<li><p>Replace any activation functions with <code class="docutils literal notranslate"><span class="pre">keras_spiking.SpikingActivation</span></code>.</p></li>
</ol>
<p><code class="docutils literal notranslate"><span class="pre">keras_spiking.SpikingActivation</span></code> can encapsulate any activation function, and will produce an equivalent spiking implementation. Neurons will spike at a rate proportional to the output of the base activation function. For example, if the activation function is outputting a value of 10, then the wrapped <code class="docutils literal notranslate"><span class="pre">SpikingActivation</span></code> will output spikes at a rate of 10Hz (i.e., 10 spikes per 1 simulated second, where 1 simulated second is equivalent to some number of timesteps, determined by the <code class="docutils literal notranslate"><span class="pre">dt</span></code>
parameter of <code class="docutils literal notranslate"><span class="pre">SpikingActivation</span></code>).</p>
<p>Note that for many layers, Keras combines the activation function into another layer. For example, <code class="docutils literal notranslate"><span class="pre">tf.keras.layers.Dense(units=10,</span> <span class="pre">activation=&quot;relu&quot;)</span></code> is equivalent to <code class="docutils literal notranslate"><span class="pre">tf.keras.layers.Dense(units=10)</span> <span class="pre">-&gt;</span> <span class="pre">tf.keras.layers.Activation(&quot;relu&quot;)</span></code>. Due to the temporal nature of <code class="docutils literal notranslate"><span class="pre">SpikingActivation</span></code> it cannot be directly used within another layer as in the first case; we need to explicitly separate it into its own layer.</p>
<ol class="arabic simple" start="3">
<li><p>Pool across time</p></li>
</ol>
<p>The output of our <code class="docutils literal notranslate"><span class="pre">keras_spiking.SpikingActivation</span></code> layer is also a timeseries. For classification, we need to aggregate that temporal information somehow to generate a final prediction. Averaging the output over time is usually a good approach (but not the only method; we could also, e.g., look at the output on the last timestep or the time to first spike). We add a <code class="docutils literal notranslate"><span class="pre">tf.keras.layers.GlobalAveragePooling1D</span></code> layer to average across the temporal dimension of the data.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># repeat the images for n_steps</span>
<span class="n">n_steps</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">train_sequences</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">train_images</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">],</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">test_sequences</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">test_images</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">],</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">spiking_model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="c1"># add temporal dimension to the input shape; we can set it to None,</span>
        <span class="c1"># to allow the model to flexibly run for different lengths of time</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span><span class="p">),</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)),</span>
        <span class="c1"># we can use Keras&#39; TimeDistributed wrapper to allow the Dense layer</span>
        <span class="c1"># to operate on temporal data</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">TimeDistributed</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">)),</span>
        <span class="c1"># replace the &quot;relu&quot; activation in the non-spiking model with a</span>
        <span class="c1"># spiking equivalent</span>
        <span class="n">keras_spiking</span><span class="o">.</span><span class="n">SpikingActivation</span><span class="p">(</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span> <span class="n">spiking_aware_training</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
        <span class="c1"># use average pooling layer to average spiking output over time</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">GlobalAveragePooling1D</span><span class="p">(),</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="c1"># train the model, identically to the non-spiking version,</span>
<span class="c1"># except using the time sequences as inputs</span>
<span class="n">train</span><span class="p">(</span><span class="n">spiking_model</span><span class="p">,</span> <span class="n">train_sequences</span><span class="p">,</span> <span class="n">test_sequences</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Epoch 1/10
1875/1875 [==============================] - 7s 4ms/step - loss: 0.5034 - accuracy: 0.8242
Epoch 2/10
1875/1875 [==============================] - 7s 4ms/step - loss: 0.3774 - accuracy: 0.8642
Epoch 3/10
1875/1875 [==============================] - 7s 4ms/step - loss: 0.3402 - accuracy: 0.8757
Epoch 4/10
1875/1875 [==============================] - 7s 4ms/step - loss: 0.3133 - accuracy: 0.8860
Epoch 5/10
1875/1875 [==============================] - 7s 4ms/step - loss: 0.2979 - accuracy: 0.8895
Epoch 6/10
1875/1875 [==============================] - 7s 4ms/step - loss: 0.2816 - accuracy: 0.8957
Epoch 7/10
1875/1875 [==============================] - 7s 4ms/step - loss: 0.2717 - accuracy: 0.8986
Epoch 8/10
1875/1875 [==============================] - 7s 4ms/step - loss: 0.2603 - accuracy: 0.9037
Epoch 9/10
1875/1875 [==============================] - 7s 4ms/step - loss: 0.2493 - accuracy: 0.9072
Epoch 10/10
1875/1875 [==============================] - 7s 4ms/step - loss: 0.2420 - accuracy: 0.9097
313/313 - 1s - loss: 11.6119 - accuracy: 0.1902 - 929ms/epoch - 3ms/step

Test accuracy: 0.19020000100135803
</pre></div></div>
</div>
<p>We can see that while the training accuracy is as good as we expect, the test accuracy is not. This is due to a unique feature of <code class="docutils literal notranslate"><span class="pre">SpikingActivation</span></code>; it will automatically swap the behaviour of the spiking neurons during training. Because spiking neurons are (in general) not differentiable, we cannot directly use the spiking activation function during training. Instead, SpikingActivation will use the base (non-spiking) activation during training, and the spiking version during inference. So
during training above we are seeing the performance of the non-spiking model, but during evaluation we are seeing the performance of the spiking model.</p>
<p>So the question is, why is the performance of the spiking model so much worse than the non-spiking equivalent, and what can we do to fix that?</p>
</div>
<div class="section" id="Simulation-time">
<h2>Simulation time<a class="headerlink" href="#Simulation-time" title="Permalink to this headline">¶</a></h2>
<p>Let’s visualize the output of the spiking model, to get a better sense of what is going on.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">check_output</span><span class="p">(</span><span class="n">seq_model</span><span class="p">,</span> <span class="n">modify_dt</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This code is only used for plotting purposes, and isn&#39;t necessary to</span>
<span class="sd">    understand the rest of this example; feel free to skip it</span>
<span class="sd">    if you just want to see the results.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># rebuild the model with the functional API, so that we can</span>
    <span class="c1"># access the output of intermediate layers</span>
    <span class="n">inp</span> <span class="o">=</span> <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">batch_shape</span><span class="o">=</span><span class="n">seq_model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">input_shape</span><span class="p">)</span>

    <span class="n">has_global_average_pooling</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">seq_model</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">GlobalAveragePooling1D</span><span class="p">):</span>
            <span class="c1"># remove the pooling so that we can see the model&#39;s</span>
            <span class="c1"># output over time</span>
            <span class="n">has_global_average_pooling</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">continue</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="p">(</span><span class="n">keras_spiking</span><span class="o">.</span><span class="n">SpikingActivation</span><span class="p">,</span> <span class="n">keras_spiking</span><span class="o">.</span><span class="n">Lowpass</span><span class="p">)):</span>
            <span class="n">cfg</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span>
            <span class="c1"># update dt, if specified</span>
            <span class="k">if</span> <span class="n">modify_dt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;dt&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">modify_dt</span>
            <span class="c1"># always return the full time series so we can visualize it</span>
            <span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;return_sequences&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>

            <span class="n">layer</span> <span class="o">=</span> <span class="nb">type</span><span class="p">(</span><span class="n">layer</span><span class="p">)(</span><span class="o">**</span><span class="n">cfg</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">keras_spiking</span><span class="o">.</span><span class="n">SpikingActivation</span><span class="p">):</span>
            <span class="c1"># save this layer so we can access it later</span>
            <span class="n">spike_layer</span> <span class="o">=</span> <span class="n">layer</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="n">func_model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">spike_layer</span><span class="o">.</span><span class="n">output</span><span class="p">])</span>

    <span class="c1"># copy weights to new model</span>
    <span class="n">func_model</span><span class="o">.</span><span class="n">set_weights</span><span class="p">(</span><span class="n">seq_model</span><span class="o">.</span><span class="n">get_weights</span><span class="p">())</span>

    <span class="c1"># run model</span>
    <span class="n">output</span><span class="p">,</span> <span class="n">spikes</span> <span class="o">=</span> <span class="n">func_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_sequences</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">has_global_average_pooling</span><span class="p">:</span>
        <span class="c1"># check test accuracy using average output over all timesteps</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># check test accuracy using output from only the last timestep</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">output</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test accuracy: </span><span class="si">{</span><span class="mi">100</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">accuracy</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>

    <span class="n">time</span> <span class="o">=</span> <span class="n">test_sequences</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">spike_layer</span><span class="o">.</span><span class="n">dt</span>
    <span class="n">n_spikes</span> <span class="o">=</span> <span class="n">spikes</span> <span class="o">*</span> <span class="n">spike_layer</span><span class="o">.</span><span class="n">dt</span>
    <span class="n">rates</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">n_spikes</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">time</span>

    <span class="nb">print</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;Spike rate per neuron (Hz): min=</span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">rates</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> &quot;</span>
        <span class="sa">f</span><span class="s2">&quot;mean=</span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">rates</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> max=</span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">rates</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="p">)</span>

    <span class="c1"># plot output</span>
    <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>

        <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">class_names</span><span class="p">[</span><span class="n">test_labels</span><span class="p">[</span><span class="n">ii</span><span class="p">]])</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">test_images</span><span class="p">[</span><span class="n">ii</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>

        <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Spikes per neuron per timestep&quot;</span><span class="p">)</span>
        <span class="n">bin_edges</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">n_spikes</span><span class="p">[</span><span class="n">ii</span><span class="p">]))</span> <span class="o">+</span> <span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.5</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ravel</span><span class="p">(</span><span class="n">n_spikes</span><span class="p">[</span><span class="n">ii</span><span class="p">]),</span> <span class="n">bins</span><span class="o">=</span><span class="n">bin_edges</span><span class="p">)</span>
        <span class="n">x_ticks</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span>
            <span class="n">x_ticks</span><span class="p">[(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">x_ticks</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">x_ticks</span><span class="p">))</span> <span class="o">&lt;</span> <span class="mf">1e-8</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">x_ticks</span> <span class="o">&gt;</span> <span class="o">-</span><span class="mf">1e-8</span><span class="p">)]</span>
        <span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;# of spikes&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Frequency&quot;</span><span class="p">)</span>

        <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Output predictions&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">test_sequences</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">*</span> <span class="n">spike_layer</span><span class="o">.</span><span class="n">dt</span><span class="p">,</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="n">ii</span><span class="p">]),</span>
        <span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">class_names</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="s2">&quot;upper left&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Time (s)&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Probability&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="o">-</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">1.05</span><span class="p">])</span>

        <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">check_output</span><span class="p">(</span><span class="n">spiking_model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
313/313 [==============================] - 1s 2ms/step
Test accuracy: 19.02%
Spike rate per neuron (Hz): min=0.00 mean=0.58 max=100.00
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_spiking-fashion-mnist_12_1.png" src="../_images/examples_spiking-fashion-mnist_12_1.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_spiking-fashion-mnist_12_2.png" src="../_images/examples_spiking-fashion-mnist_12_2.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_spiking-fashion-mnist_12_3.png" src="../_images/examples_spiking-fashion-mnist_12_3.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_spiking-fashion-mnist_12_4.png" src="../_images/examples_spiking-fashion-mnist_12_4.png" />
</div>
</div>
<p>We can see an immediate problem: the neurons are hardly spiking at all. The mean number of spikes we’re getting out of each neuron in our SpikingActivation layer is much less than one, and as a result the output is mostly flat.</p>
<p>To help understand why, we need to think more about the temporal nature of spiking neurons. Recall that the layer is set up such that if the base activation function were to be outputting a value of 1, the spiking equivalent would be spiking at 1Hz (i.e., emitting one spike per second). In the above example we are simulating for 10 timesteps, with the default <code class="docutils literal notranslate"><span class="pre">dt</span></code> of 0.001s, so we’re simulating a total of 0.01s. If our neurons aren’t spiking very rapidly, and we’re only simulating for 0.01s,
then it’s not surprising that we aren’t getting any spikes in that time window.</p>
<p>We can increase the value of <code class="docutils literal notranslate"><span class="pre">dt</span></code>, effectively running the spiking neurons for longer, in order to get a more accurate measure of the neuron’s output. Basically this allows us to collect more spikes from each neuron, giving us a better estimate of the neuron’s actual spike rate. We can see how the number of spikes and accuracy change as we increase <code class="docutils literal notranslate"><span class="pre">dt</span></code>:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># dt=0.01 * 10 timesteps is equivalent to 0.1s of simulated time</span>
<span class="n">check_output</span><span class="p">(</span><span class="n">spiking_model</span><span class="p">,</span> <span class="n">modify_dt</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
313/313 [==============================] - 1s 2ms/step
Test accuracy: 64.72%
Spike rate per neuron (Hz): min=0.00 mean=0.59 max=20.00
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_spiking-fashion-mnist_14_1.png" src="../_images/examples_spiking-fashion-mnist_14_1.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_spiking-fashion-mnist_14_2.png" src="../_images/examples_spiking-fashion-mnist_14_2.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_spiking-fashion-mnist_14_3.png" src="../_images/examples_spiking-fashion-mnist_14_3.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_spiking-fashion-mnist_14_4.png" src="../_images/examples_spiking-fashion-mnist_14_4.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">check_output</span><span class="p">(</span><span class="n">spiking_model</span><span class="p">,</span> <span class="n">modify_dt</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
313/313 [==============================] - 1s 2ms/step
Test accuracy: 88.07%
Spike rate per neuron (Hz): min=0.00 mean=0.59 max=20.00
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_spiking-fashion-mnist_15_1.png" src="../_images/examples_spiking-fashion-mnist_15_1.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_spiking-fashion-mnist_15_2.png" src="../_images/examples_spiking-fashion-mnist_15_2.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_spiking-fashion-mnist_15_3.png" src="../_images/examples_spiking-fashion-mnist_15_3.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_spiking-fashion-mnist_15_4.png" src="../_images/examples_spiking-fashion-mnist_15_4.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">check_output</span><span class="p">(</span><span class="n">spiking_model</span><span class="p">,</span> <span class="n">modify_dt</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
313/313 [==============================] - 1s 2ms/step
Test accuracy: 88.31%
Spike rate per neuron (Hz): min=0.00 mean=0.59 max=19.40
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_spiking-fashion-mnist_16_1.png" src="../_images/examples_spiking-fashion-mnist_16_1.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_spiking-fashion-mnist_16_2.png" src="../_images/examples_spiking-fashion-mnist_16_2.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_spiking-fashion-mnist_16_3.png" src="../_images/examples_spiking-fashion-mnist_16_3.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_spiking-fashion-mnist_16_4.png" src="../_images/examples_spiking-fashion-mnist_16_4.png" />
</div>
</div>
<p>We can see that as we increase <code class="docutils literal notranslate"><span class="pre">dt</span></code> the performance of the spiking model increasingly approaches the non-spiking performance. In addition, as <code class="docutils literal notranslate"><span class="pre">dt</span></code> increases, the number of spikes is increasing. To understand why this improves accuracy, keep in mind that although the simulated time is increasing, the actual number of timesteps is still 10 in all cases. We’re effectively binning all the spikes that occur on each time step. So as our bin sizes get larger (increasing <code class="docutils literal notranslate"><span class="pre">dt</span></code>), the spike counts
will more closely approximate the “true” output of the underlying non-spiking activation function.</p>
<p>One might be tempted to simply increase <code class="docutils literal notranslate"><span class="pre">dt</span></code> to a very large value, and thereby always get great performance. But keep in mind that when we do that we have likely lost any of the advantages that were motivating us to investigate spiking models in the first place. For example, one prominent advantage of spiking models is temporal sparsity (we only need to communicate occasional spikes, rather than continuous values). However, with large <code class="docutils literal notranslate"><span class="pre">dt</span></code> the neurons are likely spiking every simulation
time step (or multiple times per timestep), so the activity is no longer temporally sparse.</p>
<p>Thus setting <code class="docutils literal notranslate"><span class="pre">dt</span></code> represents a trade-off between accuracy and temporal sparsity. Choosing the appropriate value will depend on the demands of your application.</p>
<p>In some cases it can be useful to modify <code class="docutils literal notranslate"><span class="pre">dt</span></code> over the course of training. For example, we could start with a large <code class="docutils literal notranslate"><span class="pre">dt</span></code> and then gradually decrease it over time. See <code class="docutils literal notranslate"><span class="pre">keras_spiking.callbacks.DtScheduler</span></code> for more details.</p>
</div>
<div class="section" id="Spiking-aware-training">
<h2>Spiking aware training<a class="headerlink" href="#Spiking-aware-training" title="Permalink to this headline">¶</a></h2>
<p>As mentioned above, by default SpikingActivation layers will use the non-spiking activation function during training and the spiking version during inference. However, similar to the idea of <a class="reference external" href="https://www.tensorflow.org/model_optimization/guide/quantization/training">quantization aware training</a>, often we can improve performance by partially incorporating spiking behaviour during training. Specifically, we will use the spiking activation on the forward pass, while still using the non-spiking
version on the backwards pass. This allows the model to learn weights that account for the discrete, temporal nature of the spiking activities.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">spikeaware_model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span><span class="p">),</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)),</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">TimeDistributed</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">)),</span>
        <span class="c1"># set spiking_aware training and a moderate dt</span>
        <span class="n">keras_spiking</span><span class="o">.</span><span class="n">SpikingActivation</span><span class="p">(</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span> <span class="n">dt</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">spiking_aware_training</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">GlobalAveragePooling1D</span><span class="p">(),</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="n">train</span><span class="p">(</span><span class="n">spikeaware_model</span><span class="p">,</span> <span class="n">train_sequences</span><span class="p">,</span> <span class="n">test_sequences</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Epoch 1/10
1875/1875 [==============================] - 8s 4ms/step - loss: 1.1468 - accuracy: 0.6790
Epoch 2/10
1875/1875 [==============================] - 8s 4ms/step - loss: 0.6320 - accuracy: 0.7724
Epoch 3/10
1875/1875 [==============================] - 8s 4ms/step - loss: 0.5509 - accuracy: 0.8016
Epoch 4/10
1875/1875 [==============================] - 8s 4ms/step - loss: 0.5116 - accuracy: 0.8165
Epoch 5/10
1875/1875 [==============================] - 8s 4ms/step - loss: 0.4839 - accuracy: 0.8258
Epoch 6/10
1875/1875 [==============================] - 8s 4ms/step - loss: 0.4620 - accuracy: 0.8340
Epoch 7/10
1875/1875 [==============================] - 8s 4ms/step - loss: 0.4425 - accuracy: 0.8399
Epoch 8/10
1875/1875 [==============================] - 8s 4ms/step - loss: 0.4319 - accuracy: 0.8437
Epoch 9/10
1875/1875 [==============================] - 8s 4ms/step - loss: 0.4170 - accuracy: 0.8484
Epoch 10/10
1875/1875 [==============================] - 8s 4ms/step - loss: 0.4101 - accuracy: 0.8517
313/313 - 1s - loss: 0.4572 - accuracy: 0.8392 - 924ms/epoch - 3ms/step

Test accuracy: 0.8392000198364258
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">check_output</span><span class="p">(</span><span class="n">spikeaware_model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
313/313 [==============================] - 1s 2ms/step
Test accuracy: 83.92%
Spike rate per neuron (Hz): min=0.00 mean=2.86 max=70.00
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_spiking-fashion-mnist_20_1.png" src="../_images/examples_spiking-fashion-mnist_20_1.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_spiking-fashion-mnist_20_2.png" src="../_images/examples_spiking-fashion-mnist_20_2.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_spiking-fashion-mnist_20_3.png" src="../_images/examples_spiking-fashion-mnist_20_3.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_spiking-fashion-mnist_20_4.png" src="../_images/examples_spiking-fashion-mnist_20_4.png" />
</div>
</div>
<p>We can see that with <code class="docutils literal notranslate"><span class="pre">spiking_aware_training</span></code> we’re getting better performance than we were with the equivalent <code class="docutils literal notranslate"><span class="pre">dt</span></code> value above. The model has learned weights that are less sensitive to the discrete, sparse output produced by the spiking neurons.</p>
</div>
<div class="section" id="Spike-rate-regularization">
<h2>Spike rate regularization<a class="headerlink" href="#Spike-rate-regularization" title="Permalink to this headline">¶</a></h2>
<p>As we saw in the <a class="reference external" href="#Simulation-time">Simulation time section</a>, the spiking rate of the neurons is very important. If a neuron is spiking too slowly then we don’t have enough information to determine its output value. Conversely, if a neuron is spiking too quickly then we may lose the spiking advantages we are looking for, such as temporal sparsity.</p>
<p>Thus it can be helpful to more directly control the firing rates in the model by applying regularization penalties during training. Any of the standard Keras regularization functions can be used. KerasSpiking also includes some additional regularizers that can be useful for this case as they allow us to specify a non-zero reference point (so we can drive the activities towards some value greater than zero), or a range of acceptable values.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">regularized_model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span><span class="p">),</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)),</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">TimeDistributed</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">)),</span>
        <span class="n">keras_spiking</span><span class="o">.</span><span class="n">SpikingActivation</span><span class="p">(</span>
            <span class="s2">&quot;relu&quot;</span><span class="p">,</span>
            <span class="n">dt</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
            <span class="n">spiking_aware_training</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="c1"># add activity regularizer to encourage spike rates between 10 and 20 Hz</span>
            <span class="n">activity_regularizer</span><span class="o">=</span><span class="n">keras_spiking</span><span class="o">.</span><span class="n">regularizers</span><span class="o">.</span><span class="n">L2</span><span class="p">(</span>
                <span class="n">l2</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
            <span class="p">),</span>
        <span class="p">),</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">GlobalAveragePooling1D</span><span class="p">(),</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="n">train</span><span class="p">(</span><span class="n">regularized_model</span><span class="p">,</span> <span class="n">train_sequences</span><span class="p">,</span> <span class="n">test_sequences</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Epoch 1/10
1875/1875 [==============================] - 9s 4ms/step - loss: 85.8976 - accuracy: 0.6263
Epoch 2/10
1875/1875 [==============================] - 8s 4ms/step - loss: 91.3334 - accuracy: 0.6986
Epoch 3/10
1875/1875 [==============================] - 8s 4ms/step - loss: 92.9941 - accuracy: 0.7148
Epoch 4/10
1875/1875 [==============================] - 8s 4ms/step - loss: 93.9557 - accuracy: 0.7243
Epoch 5/10
1875/1875 [==============================] - 8s 4ms/step - loss: 94.5084 - accuracy: 0.7338
Epoch 6/10
1875/1875 [==============================] - 8s 4ms/step - loss: 94.9325 - accuracy: 0.7370
Epoch 7/10
1875/1875 [==============================] - 8s 4ms/step - loss: 95.3056 - accuracy: 0.7419
Epoch 8/10
1875/1875 [==============================] - 8s 4ms/step - loss: 95.6070 - accuracy: 0.7475
Epoch 9/10
1875/1875 [==============================] - 8s 4ms/step - loss: 95.8785 - accuracy: 0.7481
Epoch 10/10
1875/1875 [==============================] - 8s 4ms/step - loss: 96.1432 - accuracy: 0.7493
313/313 - 1s - loss: 96.3410 - accuracy: 0.7332 - 950ms/epoch - 3ms/step

Test accuracy: 0.7332000136375427
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">check_output</span><span class="p">(</span><span class="n">regularized_model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
313/313 [==============================] - 1s 2ms/step
Test accuracy: 73.32%
Spike rate per neuron (Hz): min=0.00 mean=10.26 max=30.00
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_spiking-fashion-mnist_24_1.png" src="../_images/examples_spiking-fashion-mnist_24_1.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_spiking-fashion-mnist_24_2.png" src="../_images/examples_spiking-fashion-mnist_24_2.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_spiking-fashion-mnist_24_3.png" src="../_images/examples_spiking-fashion-mnist_24_3.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_spiking-fashion-mnist_24_4.png" src="../_images/examples_spiking-fashion-mnist_24_4.png" />
</div>
</div>
<p>We can see that the spike rates have moved towards the 10-20 Hz target we specified. However, the test accuracy has dropped, since we’re adding an additional optimization constraint. (The accuracy is still higher than the original result with <code class="docutils literal notranslate"><span class="pre">dt=0.01</span></code>, due to the higher spike rates.) We could lower the regularization weight to allow more freedom in the firing rates. Or we could use <code class="docutils literal notranslate"><span class="pre">keras_spiking.regularizers.Percentile</span></code>, which allows more freedom for outliers. Again, this is a tradeoff
that is made between controlling the firing rates and optimizing accuracy, and the best value for that tradeoff will depend on the particular application (e.g., how important is it that spike rates fall within a particular range?).</p>
<p>Note that in some cases it may be better to use regularization with <code class="docutils literal notranslate"><span class="pre">spiking_aware_training=False</span></code>, as the regularization may perform better when the value being regularized is smoother. It may also help to adjust the weight initialization so that the initial firing rates are closer to the desired range, so that there are smaller adjustments required by the regularizer.</p>
</div>
<div class="section" id="Lowpass-filtering">
<h2>Lowpass filtering<a class="headerlink" href="#Lowpass-filtering" title="Permalink to this headline">¶</a></h2>
<p>Another tool we can employ when working with SpikingActivation layers is filtering. As we’ve seen, the output of a spiking layer consists of discrete, temporally sparse spike events. This makes it difficult to determine the spike rate of a neuron when just looking at a single timestep. In the cases above we have worked around this by using a <code class="docutils literal notranslate"><span class="pre">tf.keras.layers.GlobalAveragePooling1D</span></code> layer to average the output across all timesteps before classification.</p>
<p>Another way to achieve this is to compute some kind of moving average of the spiking output across timesteps. This is effectively what filtering is doing. KerasSpiking contains a Lowpass layer, which implements a <a class="reference external" href="https://en.wikipedia.org/wiki/Low-pass_filter">lowpass filter</a>. This has a parameter <code class="docutils literal notranslate"><span class="pre">tau</span></code>, known as the filter time constant, which controls the degree of smoothing the layer will apply. Larger <code class="docutils literal notranslate"><span class="pre">tau</span></code> values will apply more smoothing, meaning that we’re aggregating information
across longer periods of time, but the output will also be slower to adapt to changes in the input.</p>
<p>By default the <code class="docutils literal notranslate"><span class="pre">tau</span></code> values are trainable. We can use this in combination with spiking aware training to enable the model to learn time constants that best trade off spike noise versus response speed.</p>
<p>Unlike <code class="docutils literal notranslate"><span class="pre">tf.keras.layers.GlobalAveragePooling1D</span></code>, <code class="docutils literal notranslate"><span class="pre">keras_spiking.Lowpass</span></code> computes outputs for all timesteps by default. This makes it possible to apply filtering throughout the model—not only on the final layer—in the case that there are multiple spiking layers. For the final layer, we can pass <code class="docutils literal notranslate"><span class="pre">return_sequences=False</span></code> to have the layer only return the output of the final timestep, rather than the outputs of all timesteps.</p>
<p>When working with multiple KerasSpiking layers, we often want them to all share the same <code class="docutils literal notranslate"><span class="pre">dt</span></code>. We can use <code class="docutils literal notranslate"><span class="pre">keras_spiking.default.dt</span></code> to change the default dt for all layers. Note that this will only affect layers created <em>after</em> the default is changed; this will not retroactively affect previous layers.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">keras_spiking</span><span class="o">.</span><span class="n">default</span><span class="o">.</span><span class="n">dt</span> <span class="o">=</span> <span class="mf">0.01</span>

<span class="n">filtered_model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span><span class="p">),</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)),</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">TimeDistributed</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">)),</span>
        <span class="n">keras_spiking</span><span class="o">.</span><span class="n">SpikingActivation</span><span class="p">(</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span> <span class="n">spiking_aware_training</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
        <span class="c1"># add a lowpass filter on output of spiking layer</span>
        <span class="n">keras_spiking</span><span class="o">.</span><span class="n">Lowpass</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="n">train</span><span class="p">(</span><span class="n">filtered_model</span><span class="p">,</span> <span class="n">train_sequences</span><span class="p">,</span> <span class="n">test_sequences</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Epoch 1/10
1875/1875 [==============================] - 18s 9ms/step - loss: 0.8604 - accuracy: 0.7043
Epoch 2/10
1875/1875 [==============================] - 17s 9ms/step - loss: 0.5607 - accuracy: 0.7945
Epoch 3/10
1875/1875 [==============================] - 17s 9ms/step - loss: 0.5058 - accuracy: 0.8172
Epoch 4/10
1875/1875 [==============================] - 17s 9ms/step - loss: 0.4673 - accuracy: 0.8300
Epoch 5/10
1875/1875 [==============================] - 17s 9ms/step - loss: 0.4490 - accuracy: 0.8378
Epoch 6/10
1875/1875 [==============================] - 17s 9ms/step - loss: 0.4296 - accuracy: 0.8452
Epoch 7/10
1875/1875 [==============================] - 17s 9ms/step - loss: 0.4129 - accuracy: 0.8504
Epoch 8/10
1875/1875 [==============================] - 17s 9ms/step - loss: 0.3991 - accuracy: 0.8551
Epoch 9/10
1875/1875 [==============================] - 17s 9ms/step - loss: 0.3899 - accuracy: 0.8599
Epoch 10/10
1875/1875 [==============================] - 17s 9ms/step - loss: 0.3808 - accuracy: 0.8611
313/313 - 1s - loss: 0.4202 - accuracy: 0.8461 - 1s/epoch - 4ms/step

Test accuracy: 0.8460999727249146
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">check_output</span><span class="p">(</span><span class="n">filtered_model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
313/313 [==============================] - 1s 3ms/step
Test accuracy: 84.61%
Spike rate per neuron (Hz): min=0.00 mean=5.58 max=70.00
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_spiking-fashion-mnist_28_1.png" src="../_images/examples_spiking-fashion-mnist_28_1.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_spiking-fashion-mnist_28_2.png" src="../_images/examples_spiking-fashion-mnist_28_2.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_spiking-fashion-mnist_28_3.png" src="../_images/examples_spiking-fashion-mnist_28_3.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_spiking-fashion-mnist_28_4.png" src="../_images/examples_spiking-fashion-mnist_28_4.png" />
</div>
</div>
<p>We can see that the model performs similarly to the previous <a class="reference external" href="#Spiking-aware-training">spiking aware training</a> example, which makes sense since, for a static input image, a moving average is very similar to a global average. We would need a more complicated model, with multiple spiking layers or inputs that are changing over time, to really see the benefits of a Lowpass layer. The <code class="docutils literal notranslate"><span class="pre">keras_spiking.Alpha</span></code> layer is another lowpass-filtering layer, which can provide better filtering of spike
noise with less delay than <code class="docutils literal notranslate"><span class="pre">keras_spiking.Lowpass</span></code>.</p>
</div>
<div class="section" id="Summary">
<h2>Summary<a class="headerlink" href="#Summary" title="Permalink to this headline">¶</a></h2>
<p>We can use <code class="docutils literal notranslate"><span class="pre">SpikingActivation</span></code> layers to convert any activation function to an equivalent spiking implementation. Models with SpikingActivations can be trained and evaluated in the same way as non-spiking models, thanks to the swappable training/inference behaviour.</p>
<p>There are also a number of additional features that should be kept in mind in order to optimize the performance of a spiking model:</p>
<ul class="simple">
<li><p><a class="reference external" href="#Simulation-time">Simulation time</a>: by adjusting <code class="docutils literal notranslate"><span class="pre">dt</span></code> we can trade off temporal sparsity versus accuracy</p></li>
<li><p><a class="reference external" href="#Spiking-aware-training">Spiking aware training</a>: incorporating spiking dynamics on the forward pass can allow the model to learn weights that are more robust to spiking activations</p></li>
<li><p><a class="reference external" href="#Spike-rate-regularization">Spike rate regularization</a>: we can gain more control over spike rates by directly incorporating activity regularization into the optimization process</p></li>
<li><p><a class="reference external" href="#Lowpass-filtering">Lowpass filtering</a>: we can achieve better accuracy with fewer spikes by aggregating spike data over time</p></li>
</ul>
</div>
</div>


            </div>
          </div>
        </div>
      </div>

    </div>
  </div>
</div><footer class="text-light footer-main gradient-bottom-center">
  <p class="text-center">
    <a class="no-hover-line" href="https://appliedbrainresearch.com">
      <img
        class="abr-logo"
        src="https://www.nengo.ai/img/abr-logo.svg"
        height="32"
      />
    </a>
    <a href="https://www.nengo.ai/">What is Nengo?</a>
    <a href="https://www.nengo.ai/examples/">Examples</a>
    <a href="https://www.nengo.ai/documentation/">Documentation</a>
    <a href="https://www.nengo.ai/store/">Store</a>
    <a href="https://www.nengo.ai/getting-started/">Getting started</a>
    <a href="https://www.nengo.ai/privacy/">Privacy</a>
  </p>
  <p class="small text-center pb-0 mb-0">&copy; Applied Brain Research</p>
</footer>
<script>
  var elements = document.querySelectorAll('.sidenav');
  Stickyfill.add(elements);
</script>
<script>
  ScrollReveal().reveal(".fade-in", {
      scale: 0.85,
      duration: 1000,
      delay: 250,
      interval: 50
  });
</script>
<script>
  $('a.toggle-sidenav').on('click', function(e) {
    e.preventDefault();
    if ( $(this).hasClass('active') ) {
      $(this).removeClass('active');
      $('.sidenav').removeClass('open');
    } else {
      $(this).addClass('active');
      $('.sidenav').addClass('open');
    }
  });
</script>
<script>
  var lists = document.querySelectorAll('.toctree ul');
  lists.forEach((ul) => {
      ul.classList.add("nav");
  });
  var links = document.querySelectorAll('.toctree a');
  links.forEach((link) => {
      link.classList.add("nav-link");
  });
  $("body").scrollspy({target: ".sidenav"});
</script>
  </body>
</html>